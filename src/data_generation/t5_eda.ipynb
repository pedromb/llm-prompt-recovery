{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "device = \"cpu\"\n",
    "\n",
    "def get_embds_score(t5, pred, gt):\n",
    "    pred_embds = t5.encode(pred, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1)\n",
    "    gt_embds = t5.encode(gt, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1)\n",
    "\n",
    "    res = abs((cosine_similarity(gt_embds, pred_embds)) ** 3)\n",
    "\n",
    "    return res[0][0]\n",
    "\n",
    "def calc_score(t5, prompt, embds):\n",
    "    prompt_embds = t5.encode(prompt, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1)\n",
    "    res = ((cosine_similarity(embds, prompt_embds)) ** 3).mean()\n",
    "    return res\n",
    "\n",
    "def get_dataset_pedro():\n",
    "    prompts = json.load(open(\"prompts_selected.json\"))\n",
    "    df = pd.DataFrame({\"rewrite_prompt\": prompts})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = SentenceTransformer(\"sentence-transformers/sentence-t5-base\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = get_dataset_pedro()\n",
    "embds = t5.encode(df_gpt[\"rewrite_prompt\"].tolist(), normalize_embeddings=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.', embds))\n",
    "print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.</s>', embds))\n",
    "print(calc_score(t5, 'Improve the text to this.', embds))\n",
    "print(calc_score(t5, 'Improve the text to this.</s>', embds))\n",
    "print(calc_score(t5, 'Rewrite the text to this.', embds))\n",
    "print(calc_score(t5, 'Rewrite the text to this.</s>', embds))\n",
    "print(calc_score(t5, 'Modify text better.', embds))\n",
    "print(calc_score(t5, 'Improve rephrase text manner this written to has language tone within to ', embds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.', embds))\n",
    "print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.</s>', embds))\n",
    "print(calc_score(t5, 'Improve the text to this.', embds))\n",
    "print(calc_score(t5, 'Improve the text to this.</s>', embds))\n",
    "print(calc_score(t5, 'Rewrite the text to this.', embds))\n",
    "print(calc_score(t5, 'Rewrite the text to this.</s>', embds))\n",
    "print(calc_score(t5, 'Reword text better through things involved human expressed retell mentee item to create ensuing simple the following please atuin prospective', embds))\n",
    "print(calc_score(t5, 'Modify text better conveying described to human mentee this following body out it of language from on this is about.', embds))\n",
    "print(calc_score(t5, 'Improve text rephrase narrative tone to this .', embds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = t5.tokenizer(['Improve the text to this.</s>'], return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "\n",
    "print(t5.tokenizer.batch_decode(tids[\"input_ids\"]))\n",
    "\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    tembds = t5(tids)[\"sentence_embedding\"].cpu().numpy()\n",
    "\n",
    "cos_sim = (cosine_similarity(tembds, embds) ** 3).mean()\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_most_common_ngrams(texts, n=2, top_n=5):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    count_values = X.toarray().sum(axis=0)\n",
    "    vocabulary = vectorizer.vocabulary_\n",
    "    freq_dist = Counter(dict(zip(vocabulary.keys(), count_values)))\n",
    "    return freq_dist.most_common(top_n)\n",
    "\n",
    "n_grams = get_most_common_ngrams(df_gpt[\"rewrite_prompt\"].tolist(), n=2, top_n=10)\n",
    "\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = {}\n",
    "text_list = df_gpt[\"rewrite_prompt\"].tolist()\n",
    "for i, text in enumerate(text_list):    \n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        word = \"\".join(filter(str.isalnum, word)).lower().strip()\n",
    "        if not word:\n",
    "            continue\n",
    "        if word not in bow:\n",
    "            bow[word] = 0\n",
    "        bow[word] += 1\n",
    "bow_tup = [(k, v) for k, v in bow.items()]\n",
    "sorted_bow = sorted(bow_tup, key=lambda x: x[1], reverse=True)\n",
    "sorted_bow = list(sorted_bow)[:1000]\n",
    "all_words = [tup[0] for tup in sorted_bow]\n",
    "all_words = [w for w in all_words if w not in (\"portrayal\", \"conveying\", \"convey\", \"compelling\", \"compel\", \"expressing\", \"improving\", \"retell\", \"reword\", \"engaging\", \"storytelling\")]\n",
    "len(all_words), all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_width = 50  # Number of beams to keep after each step\n",
    "num_words = 12  # Total number of words to generate\n",
    "all_beams = [([], 0)]  # Starting with empty sequence and 0 score\n",
    "pbar = tqdm(range(num_words))\n",
    "for step in pbar:\n",
    "    new_beams = []\n",
    "    for sel_words, score in all_beams:\n",
    "        cur_text = \" \".join(sel_words)\n",
    "        if sel_words:\n",
    "            cur_text += \" \"\n",
    "        all_text = [cur_text + word for word in all_words]\n",
    "       \n",
    "        for i, t in enumerate(all_text):\n",
    "            t = t[0].upper() + t[1:]\n",
    "            if len(t.split()) > 3:\n",
    "                t = t + \".\"\n",
    "            all_text[i] = t\n",
    "\n",
    "        if not sel_words:  # Capitalize the first word of the sentence\n",
    "            all_text = [t[0].upper() + t[1:] for t in all_text]\n",
    "        text_embds = t5.encode(all_text, normalize_embeddings=True, show_progress_bar=False)\n",
    "        scores = (cosine_similarity(embds, text_embds) ** 3).mean(axis=0)\n",
    "        for i, new_score in enumerate(scores):\n",
    "            new_beams.append((sel_words + [all_words[i]], new_score))\n",
    "    # Keep only the best `beam_width` beams\n",
    "    all_beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "    best = all_beams[0]\n",
    "    pbar.set_description(best[1], \" \".join(best[0]))\n",
    "\n",
    "# Select the best beam\n",
    "best_words, best_score = max(all_beams, key=lambda x: x[1])\n",
    "print(\" \".join(best_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
