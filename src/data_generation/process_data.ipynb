{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "data.dropna(inplace=True)  \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rewrite_prompt\n",
    "data = data.loc[\n",
    "    ~(\n",
    "        data.rewrite_prompt.str.contains(\"Translate\", case=False) &\n",
    "        data.rewrite_prompt.str.contains(\"from\", case=False) &\n",
    "        data.rewrite_prompt.str.contains(\"to\", case=False)\n",
    "    )\n",
    "]\n",
    "print(data.shape)\n",
    "words_to_remove = [\"painting\", \"logo\", \"programming\", \"json\", \"html\", \"markdown\", \"python\", \"java\", \"audio\", \"visual\", \"storyboard\"]\n",
    "for word in words_to_remove:\n",
    "   data = data.loc[\n",
    "      ~(data.rewrite_prompt.str.contains(word, regex=False, case=False))\n",
    "   ]\n",
    "print(data.shape)\n",
    "data = data.loc[\n",
    "    ~(\n",
    "        data.rewrite_prompt.str.contains(\"code\", case=False) &\n",
    "        data.rewrite_prompt.str.contains(\"language\", case=False)\n",
    "    )\n",
    "]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â Process rewritten text\n",
    "data[\"first_phrase\"] = data.rewritten_text.str.strip().str.split(\"\\\\n\", expand=True)[0]\n",
    "\n",
    "def remove_first_phrase(x):\n",
    "    return x.rewritten_text.replace(x.first_phrase, \"\")\n",
    "\n",
    "data.loc[\n",
    "    data.first_phrase.str.contains(\"##\", case=False), \"rewritten_text\"\n",
    "] = data.loc[\n",
    "    data.first_phrase.str.contains(\"##\", case=False)\n",
    "].apply(remove_first_phrase, axis=1)\n",
    "\n",
    "data.loc[\n",
    "    data.first_phrase.str.contains(\"\\*\\*\", case=False), \"rewritten_text\"\n",
    "] = data.loc[\n",
    "    data.first_phrase.str.contains(\"\\*\\*\", case=False)\n",
    "].apply(remove_first_phrase, axis=1)\n",
    "\n",
    "data.loc[\n",
    "    data.first_phrase.str.contains(\"sure\", case=False) |\n",
    "    data.first_phrase.str.contains(\"here's\", case=False), \"rewritten_text\"\n",
    "] = data.loc[\n",
    "    data.first_phrase.str.contains(\"sure\", case=False) |\n",
    "    data.first_phrase.str.contains(\"here's\", case=False)\n",
    "].apply(remove_first_phrase, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\n",
    "    data.first_phrase.str.contains(\"\\*\\*\", case=False), \"rewritten_text\"\n",
    "] = data.loc[\n",
    "    data.first_phrase.str.contains(\"\\*\\*\", case=False)\n",
    "].apply(remove_first_phrase, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove texts where rewritten_text == original_text\n",
    "data = data.loc[\n",
    "    ~(data.rewritten_text == data.original_text)\n",
    "]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\n",
    "    \"i am not able\",\n",
    "    \"i'm not able\",\n",
    "    \"text does not\",\n",
    "    \"text doesn't\",\n",
    "    \"i am unable\",\n",
    "    \"i'm unable\",\n",
    "    \"i will not provide\",\n",
    "    \"i won't provide\",\n",
    "    \"inappropriate\",\n",
    "    \"the rewritten text\",\n",
    "    \"the transformed text\",\n",
    "    \"text rewritten\",\n",
    "    \"text transformed\",\n",
    "    \"here is the text\",\n",
    "    \"text you provided\",\n",
    "    \"text provided\",\n",
    "    \"does not describe\",\n",
    "    \"certainly\"\n",
    "\n",
    "]\n",
    "for word in to_remove:\n",
    "    data = data.loc[\n",
    "        ~data.rewritten_text.str.contains(word, case=False)\n",
    "    ]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_ratio\"] = data.progress_apply(lambda x: fuzz.ratio(x.original_text, x.rewritten_text), axis=1)\n",
    "# Remove texts where text_ratio > 95\n",
    "data = data.loc[data.text_ratio < 95]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "def is_redundant_pattern(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    # Loop through the tagged tokens to find a noun followed by \"to be\" and a verb pattern\n",
    "    for i in range(len(tagged)-3):\n",
    "        if tagged[i][1].startswith('NN') and tagged[i+1][0].lower() == 'to' and tagged[i+2][0].lower() == 'be' and tagged[i+3][1].startswith('VBN'):                \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"is_redudant\"] = data.rewrite_prompt.progress_apply(is_redundant_pattern)\n",
    "data = data.loc[~data.is_redudant]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"id\", \"original_text\", \"rewrite_prompt\", \"rewritten_text\", \"cluster\"]].drop_duplicates().dropna()\n",
    "data[\"rewritten_text\"] = data.rewritten_text.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../../data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add prompt variations and get new dataset\n",
    "# import json\n",
    "# prompt_variations = json.load(open(\"/home/llm-prompt-recovery/data/prompt_variations.json\"))\n",
    "# new_data = pd.read_csv(\"../../data/new_data.csv\")\n",
    "# old_data = pd.read_csv(\"../../data/data.csv\")\n",
    "# all_data = pd.concat([data, new_data])\n",
    "# prompts_to_keep = list(prompt_variations.keys())\n",
    "# for v in prompt_variations.values():\n",
    "#     prompts_to_keep.extend(v)\n",
    "# prompts_to_keep = set(prompts_to_keep)\n",
    "# all_data = all_data.loc[all_data.rewrite_prompt.isin(prompts_to_keep)]\n",
    "# original_text_counts = all_data.original_text.value_counts()\n",
    "# texts_to_keep = original_text_counts[original_text_counts > 1].index.values\n",
    "# all_data = all_data.loc[all_data.original_text.isin(texts_to_keep)]\n",
    "# all_data.to_csv(\"../../data/new_data_for_training.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
